<!DOCTYPE html>
<html>
<head>
  <title>Risks and Challenges</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
<p>While GenAI is powerful, it is far from perfect. Understanding its limitations is critical for responsible use.
</p>
  <p>
    <strong>1. Hallucinations</strong></p>
  <p>AI models are "stochastic," meaning they predict the next word based on probability, not facts. This leads to hallucinations—where the AI confidently provides information that is completely fabricated or factually incorrect.</p>
  </p>
  <p><strong>Example:</strong> Asking an AI for legal citations might result in it "inventing" non-existent court cases that sound perfectly real.</p>
  
<p>
  <strong>2. Data Privacy & Leakage</strong> </p>
  <p>As seen in the Samsung Leak(2023), any data you feed into a public AI model can be ingested and used to train future versions. This makes your "secret sauce"—proprietary code, internal memos, or customer data—publicly accessible intelligence for your competitors.</p>

  <p><strong>3. Bias & Fairness</strong></p>
  
<p>AI models are trained on the internet, which contains human biases. If the training data is prejudiced, the AI’s output will be too. This can lead to unfair outcomes in hiring, lending, or social interactions.</p>



<p><strong>4. Intellectual Property (IP)</strong></p>
  <p>Who owns an AI-generated image or block of code? Current legal frameworks are still debating whether AI training constitutes "fair use" of copyrighted material and who holds the rights to the final output.</p>
<p><strong>Cybersecurity & Deepfakes</strong></p>
  <p>
<ul>
  <p><strong>Prompt Injection:</strong> Malicious users can "trick" an AI into bypassing its safety filters to generate harmful content.</p>
  <p><strong>Deepfakes:</strong> AI can create hyper-realistic audio and video of real people, leading to sophisticated fraud and misinformation campaigns.</p>
</ul>
    
  </p>
  
  <p><a href="genai.html">← Back to GenAI Topics</a></p>

</body>
</html>
